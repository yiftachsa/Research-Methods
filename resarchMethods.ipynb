{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXNEfm9XrkdZ"
      },
      "source": [
        "# source: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def plot_history(history, titles):\n",
        "    plot_loss(history, 1, titles[0])\n",
        "    plot_accuracy(history, 2, titles[1])\n",
        "\n",
        "\n",
        "def plot_loss(history, fig_num, title):\n",
        "    \"\"\"\n",
        "    Plots the training (and dev) loss from the given training history\n",
        "    :param history: the training history to plot, also containing the dev loss\n",
        "    :param fig_num: integer - the plot figure index\n",
        "    \"\"\"\n",
        "    plt.figure(fig_num)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_accuracy(history, fig_num, title):\n",
        "    \"\"\"\n",
        "    Plots the training (and dev) accuracy from the given training history\n",
        "    :param history: the training history to plot, also containing the dev accuracy\n",
        "    :param fig_num: integer - the plot figure index\n",
        "    \"\"\"\n",
        "    plt.figure(fig_num)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgGgjy1Rrmnz"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "def evaluate_metrics(y, y_hat):\n",
        "    \"\"\"\n",
        "    Computes CategoricalAccuracy, Top1Accuracy and Top5Accuracy\n",
        "    :param y: the ground truth values\n",
        "    :param y_hat: the predicted values\n",
        "    :return: CategoricalAccuracy, Top1Accuracy and Top5Accuracy\n",
        "    \"\"\"\n",
        "    acc = accuracy_score(y, y_hat)\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    auc = roc_auc_score(y, y_hat)\n",
        "    print(f\"AUC: {auc}\")\n",
        "    print(classification_report(y, y_hat))\n",
        "    cnf_mat = confusion_matrix(y, y_hat)\n",
        "    ConfusionMatrixDisplay(cnf_mat, display_labels=[0, 1]).plot(values_format='d')\n",
        "\n",
        "\n",
        "def evaluate_accuracy(y, y_hat):\n",
        "    acc = accuracy_score(y, y_hat)\n",
        "    return acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHmeV5QCsNh0",
        "outputId": "b1f23752-00fe-4c54-e0b4-f6c548c802fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMjD7BYorSSN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "b3df7574-fb9f-486c-f803-ebc4a63689ef"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shutil import copyfile\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "def convert_illness_level(x):\n",
        "    if x == 6:\n",
        "        return 0\n",
        "    elif x > 2.5:\n",
        "        return 1  #\n",
        "    else:\n",
        "        return 0  # sick\n",
        "\n",
        "\n",
        "def load_real_labels():\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/resarchMethods/rating.csv\")\n",
        "    df = df[df.rating != -1]\n",
        "    df[\"healthy\"] = df.rating.apply(convert_illness_level)\n",
        "    return df[[\"image\", \"healthy\"]]\n",
        "\n",
        "\n",
        "def split_sets(df):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df[\"image\"], df[\"healthy\"], train_size=0.7,\n",
        "                                                        random_state=1)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def basic_preprocess(image):\n",
        "    \"\"\"\n",
        "    preprocess a given image for the DCGAN256 model.\n",
        "    :param image: PIL Image - the original image\n",
        "    :return: ndarray - the image after preprocess\n",
        "    \"\"\"\n",
        "    # image = np.array(image.convert('RGB'), dtype='float32')\n",
        "\n",
        "    # image = image / 255\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_and_preprocess(img_path, preprocess):\n",
        "    \"\"\"\n",
        "    Load and preprocess an image from the given img_path.\n",
        "    :param img_path: String - a path to an image\n",
        "    :param preprocess: function - a function for image preprocessing\n",
        "    :return: preprocessed image\n",
        "    \"\"\"\n",
        "    # load the input image using the Keras helper utility while ensuring\n",
        "    # the image is resized to `image_shape`\n",
        "    image = load_img(img_path, target_size=(256, 256))\n",
        "\n",
        "    image = img_to_array(image)\n",
        "    # our input image is now represented as a NumPy array of shape\n",
        "    # (inputShape[0], inputShape[1], 3) however we need to expand the\n",
        "    # dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
        "    # so we can pass it through the network\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    # pre-process the image using the appropriate function based on the\n",
        "    # model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
        "    image = preprocess(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_images_from_path(img_folder_path, preprocess):\n",
        "    \"\"\"\n",
        "    Loads and preprocess images from a given folder path.\n",
        "    Uses the appropriate preprocessing method for the chosen model.\n",
        "    returns a list of the preprocessed images and a list of their names.\n",
        "    :param preprocess: function - a function for image preprocessing\n",
        "    :param input_shape: tuple - the dimensions of the image that will be loaded\n",
        "    :param img_folder_path: String - a path to a folder that contains images.\n",
        "    :param model_name: String - a convolutional model name\n",
        "    :return: images, images_names - list - lists of the preprocessed images and the images names\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    images_names = []\n",
        "    for img_path in os.listdir(img_folder_path):  # load all images into a list\n",
        "        full_img_path = os.path.join(img_folder_path, img_path)\n",
        "        img = load_and_preprocess(full_img_path, preprocess)\n",
        "        # appending\n",
        "        images_names.append(img_path)\n",
        "        images.append(img)\n",
        "    return np.vstack(images), images_names\n",
        "\n",
        "\n",
        "def set_from_names(names_in_set, samples, samples_names):\n",
        "    samples_in_set = []\n",
        "    for sample_name in names_in_set:\n",
        "        sample_index = samples_names.index(sample_name)\n",
        "        sample = samples[sample_index]\n",
        "        samples_in_set.append(sample)\n",
        "    return samples_in_set\n",
        "\n",
        "\n",
        "# Load ground truth labels and samples names\n",
        "df_labels = load_real_labels()\n",
        "\n",
        "# Split sets\n",
        "X_train_names, X_test_names, y_train, y_test = split_sets(df_labels)\n",
        "\n",
        "X_train_names = X_train_names.values\n",
        "X_test_names = X_test_names.values\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        "\n",
        "# Load entire datasets\n",
        "src = '/content/drive/MyDrive/resarchMethods/labeled_data'\n",
        "images, images_names = load_images_from_path(\n",
        "    img_folder_path=\"/content/drive/MyDrive/resarchMethods/labeled_data\",\n",
        "    preprocess=basic_preprocess)\n",
        "\n",
        "# split samples\n",
        "X_train = set_from_names(X_train_names, images, images_names)\n",
        "X_test = set_from_names(X_test_names, images, images_names)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Pre processing and data augmentation\n",
        "data_generator_train = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        ")\n",
        "data_generator_test = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rescale=1. / 255,\n",
        ")\n",
        "# compute quantities required for featurewise normalization\n",
        "# std, mean\n",
        "data_generator_train.fit(X_train)\n",
        "data_generator_test.fit(X_train)\n",
        "\n",
        "# models\n",
        "# Loading the pre-trained models weights\n",
        "pre_trained_resnet_model = ResNet50(input_shape=(256, 256, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "pre_trained_inception_model = InceptionV3(input_shape=(256, 256, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "# Adapting the model\n",
        "for layer in pre_trained_inception_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in pre_trained_resnet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_layer_inception_model = pre_trained_inception_model.get_layer('mixed10')\n",
        "print('inception: last layer output shape:', last_layer_inception_model.output_shape)\n",
        "last_output_inception_model = last_layer_inception_model.output\n",
        "\n",
        "last_layer_resnet_model = pre_trained_resnet_model.get_layer('conv5_block3_out')\n",
        "print('resnet_model: last layer output shape:', last_layer_resnet_model.output_shape)\n",
        "last_output_resnet_model = last_layer_resnet_model.output\n",
        "\n",
        "\n",
        "def transfer_model_init(pre_trained_model, last_output_layer, learning_rate):\n",
        "    # Flatten the output layer to 1 dimension\n",
        "    x = layers.Flatten()(last_output_layer)\n",
        "    # Add a fully connected layer with 2,048 hidden units and ReLU activation\n",
        "    x = layers.Dense(2048, activation='relu')(x)\n",
        "    # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "    x = layers.Dense(1024, activation='relu')(x)\n",
        "    # Add a final sigmoid layer for classification\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Configure and compile the model\n",
        "    model = Model(pre_trained_model.input, x)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# transfer_inception_model = transfer_model_init(pre_trained_inception_model, last_output_inception_model,\n",
        "#                                                learning_rate=0.0001)\n",
        "\n",
        "# transfer_resnet_model = transfer_model_init(pre_trained_resnet_model, last_output_resnet_model, learning_rate=0.0001)\n",
        "\n",
        "# print(f\"len(x_test_transformed): {len(x_test_transformed)}\")\n",
        "# resnet_test_y_hat = transfer_resnet_model.predict(x_test_transformed)\n",
        "x_test_transformed = data_generator_test.standardize(X_test)\n",
        "\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "\n",
        "\n",
        "def train_model(epochs, batch_size, learning_rate, pre_trained_model, last_output,\n",
        "                iterations):  # inception_training_history\n",
        "    best_model = None\n",
        "    second_best_model = None\n",
        "    best_model_history = None\n",
        "    best_test_accuracy = 0\n",
        "    for i in range(iterations):\n",
        "        model = transfer_model_init(pre_trained_model, last_output,\n",
        "                                    learning_rate=learning_rate)\n",
        "        history = model.fit(\n",
        "            data_generator_train.flow(X_train, y_train, batch_size=batch_size),\n",
        "            steps_per_epoch=len(X_train) / batch_size, epochs=epochs,\n",
        "            validation_data=(\n",
        "                x_test_transformed, y_test))  # data_generator_test.flow(X_test, y_test, batch_size=batch_size))\n",
        "\n",
        "        test_y_hat = model.predict(x_test_transformed)\n",
        "        test_y_hat = [0 if x < 0.5 else 1 for x in test_y_hat]\n",
        "\n",
        "        if evaluate_accuracy(y_test, test_y_hat) > best_test_accuracy:\n",
        "            best_test_accuracy = evaluate_accuracy(y_test, test_y_hat)\n",
        "            second_best_model = best_model\n",
        "            best_model = model\n",
        "            best_model_history = history\n",
        "    return best_model, best_model_history, best_test_accuracy, second_best_model\n",
        "\n",
        "\n",
        "def save_model(model, path, num):\n",
        "    # serialize model to JSON\n",
        "    model_json = model.to_json()\n",
        "    with open(path + \"\\\\model_{}.json\".format(num), \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(path + \"\\\\model_weights_{}.h5\".format(num))\n",
        "\n",
        "\n",
        "def load_model(path, num):\n",
        "    # load json and create model\n",
        "    json_file = open(path + '\\\\model_{}.json'.format(num), 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    model.load_weights(path + \"\\\\model_weights_{}.h5\".format(num))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# transfer_inception_model, inception_training_history, inception_best_test_accuracy, second_best_transfer_inception_model = train_model(\n",
        "#     epochs=10, batch_size=32, learning_rate=0.0001, pre_trained_model=pre_trained_inception_model,\n",
        "#     last_output=last_output_inception_model, iterations=5)\n",
        "# print(f\"inception_best_test_accuracy: {inception_best_test_accuracy}\\n\")\n",
        "# save_model(model=transfer_inception_model,\n",
        "#            path=\"/content/drive/MyDrive/resarchMethods/trainedModels/transfer_inception\",\n",
        "#            num=10)\n",
        "# save_model(model=second_best_transfer_inception_model,\n",
        "#            path=\"/content/drive/MyDrive/resarchMethods/trainedModels/transfer_inception\",\n",
        "#            num=11)\n",
        "\n",
        "transfer_resnet_model, resnet_training_history, resnet_best_test_accuracy, second_best_transfer_resnet_model = train_model(\n",
        "    epochs=5, batch_size=16, learning_rate=0.0001, pre_trained_model=pre_trained_resnet_model,\n",
        "    last_output=last_output_resnet_model, iterations=2)\n",
        "print(f\"resnet_best_test_accuracy: {resnet_best_test_accuracy}\\n\")\n",
        "save_model(model=transfer_resnet_model,\n",
        "           path=\"/content/drive/MyDrive/resarchMethods/trainedModels/transfer_resnet\",\n",
        "           num=100)\n",
        "\n",
        "# save_model(model=second_best_transfer_resnet_model,\n",
        "#            path=\"/content/drive/MyDrive/resarchMethods/trainedModels/transfer_resnet\",\n",
        "#            num=11)\n",
        "\n",
        "# RESULTS\n",
        "plot_history(inception_training_history, [\"InceptionV3 Loss\", \"InceptionV3 Accuracy\"])\n",
        "plot_history(resnet_training_history, [\"ResNet50 Loss\", \"ResNet50 Accuracy\"])\n",
        "\n",
        "resnet_test_y_hat = transfer_resnet_model.predict(x_test_transformed)\n",
        "resnet_test_y_hat = [0 if x < 0.5 else 1 for x in resnet_test_y_hat]\n",
        "print(\"ResNet50 results:\")\n",
        "evaluate_metrics(y_test, resnet_test_y_hat)\n",
        "\n",
        "inception_test_y_hat = transfer_inception_model.predict(x_test_transformed)\n",
        "inception_test_y_hat = [0 if x < 0.5 else 1 for x in inception_test_y_hat]\n",
        "print(\"InceptionV3 results:\")\n",
        "evaluate_metrics(y_test, inception_test_y_hat)\n",
        "\n",
        "# USER STUDY\n",
        "X_user_test_names = [\"20200916_171401_color_0_269_7_550_323_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_171639_color_0_365_31_699_297_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200903_183547_color_0_638_256_828_403_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200903_184103_color_0_289_250_473_422_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_181531_color_0_502_31_703_285_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_171959_color_0_200_58_583_307_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_182356_color_0_466_32_649_199_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_173050_color_0_332_17_670_342_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_175634_color_0_311_39_669_328_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_183002_color_0_471_295_640_463_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_183524_color_0_128_124_384_385_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_183925_color_0_576_38_740_228_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_182123_color_0_335_102_748_376_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_171334_color_0_417_177_653_390_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_171405_color_0_345_149_537_380_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_185532_color_0_538_127_836_431_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_185756_color_0_230_13_418_156_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_171412_color_0_232_160_531_381_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_174842_color_0_363_194_734_441_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_175935_color_0_340_101_626_412_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_180124_color_0_345_170_702_407_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_174948_color_0_297_96_735_339_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_171726_color_0_330_266_594_469_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_181100_color_0_298_163_659_400_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_175552_color_0_522_19_760_232_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_183303_color_0_353_98_691_430_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200903_181929_color_0_153_182_371_455_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_172836_color_0_343_120_640_417_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200903_181824_color_0_587_226_818_398_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200916_173040_color_0_355_169_660_415_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200903_184822_color_0_112_229_328_411_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_171743_color_0_323_90_680_468_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_173933_color_0_343_211_662_466_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_182350_color_0_484_18_674_215_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_174418_color_0_377_117_650_361_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_175450_color_0_387_247_665_467_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_183653_color_0_605_289_761_469_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_184634_color_0_496_85_635_215_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_184742_color_0_455_151_624_283_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_175935_color_0_340_101_626_412_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_172008_color_0_321_105_739_466_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200903_185411_color_0_60_238_146_323_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_180753_color_0_428_280_565_397_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_173000_color_0_347_200_609_452_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_181849_color_0_618_185_832_418_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200909_182055_color_0_307_199_496_443_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200924_173805_color_0_196_62_495_274_zssr_X4.00X4.00.jpg\",\n",
        "                     \"20200903_185154_color_0_677_266_833_389_zssr_X4.00X4.00.jpg\"]\n",
        "\n",
        "y_user_test = [0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
        "               0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1]\n",
        "\n",
        "X_user_test = []\n",
        "\n",
        "for sample_name in X_user_test_names:\n",
        "    sample_index = images_names.index(sample_name)\n",
        "    sample = images[sample_index]\n",
        "    X_user_test.append(sample)\n",
        "X_user_test = np.array(X_user_test)\n",
        "X_user_test = data_generator_test.standardize(X_user_test)\n",
        "\n",
        "y_hat_inception_user_study = transfer_inception_model.predict(X_user_test)\n",
        "y_hat_inception_user_study = [0 if x < 0.5 else 1 for x in y_hat_inception_user_study]\n",
        "\n",
        "y_hat_users_user_study = [0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
        "                          0, 1, 1, 0,\n",
        "                          1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1]\n",
        "\n",
        "# USER STUDY EVALUATION\n",
        "print(\"InceptionV3 user study results:\")\n",
        "evaluate_metrics(y_user_test, y_hat_inception_user_study)\n",
        "\n",
        "print(\"Users user study results:\")\n",
        "evaluate_metrics(y_user_test, y_hat_users_user_study)\n",
        "\n",
        "### Statistical tests\n",
        "\n",
        "# Model to model\n",
        "\n",
        "\n",
        "# r = set_from_names([\"sn1\", \"sn3\"], [\"s1\", \"s2\", \"s3\"], [\"sn1\",\"sn2\",\"sn3\"])\n",
        "\n",
        "# dst_0 = 'D:\\Documents\\Studies\\Documents for higher education\\Courses\\Year 4 Semester 1\\שיטות מחקר\\עבודות להגשה\\\\user study\\\\0'\n",
        "# dst_1 = 'D:\\Documents\\Studies\\Documents for higher education\\Courses\\Year 4 Semester 1\\שיטות מחקר\\עבודות להגשה\\\\user study\\\\1'\n",
        "\n",
        "# limit_0 = 27\n",
        "# limit_1 = 33\n",
        "# count_0 = 0\n",
        "# count_1 = 0\n",
        "# for idx, image_name in enumerate(X_test.values):\n",
        "#     full_file_path = os.path.join(src, image_name)\n",
        "#\n",
        "#     if y_test.values[idx] == 0 and count_0 < limit_0:\n",
        "#         dst_file_path = os.path.join(dst_0, image_name)\n",
        "#         copyfile(full_file_path, dst_file_path)\n",
        "#         count_0 += 1\n",
        "#     elif y_test.values[idx] == 1 and count_1 < limit_1:\n",
        "#         dst_file_path = os.path.join(dst_1, image_name)\n",
        "#         copyfile(full_file_path, dst_file_path)\n",
        "#         count_1 += 1\n",
        "#\n",
        "#     if count_0 + count_1 == 60:\n",
        "#         break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "inception: last layer output shape: (None, 6, 6, 2048)\n",
            "resnet_model: last layer output shape: (None, 8, 8, 2048)\n",
            "Epoch 1/5\n",
            "36/36 [==============================] - 227s 6s/step - loss: 1.9751 - accuracy: 0.6246 - val_loss: 0.5713 - val_accuracy: 0.7171\n",
            "Epoch 2/5\n",
            "36/36 [==============================] - 218s 6s/step - loss: 0.6272 - accuracy: 0.7275 - val_loss: 1.7053 - val_accuracy: 0.5378\n",
            "Epoch 3/5\n",
            "36/36 [==============================] - 219s 6s/step - loss: 0.7281 - accuracy: 0.7225 - val_loss: 0.5768 - val_accuracy: 0.7450\n",
            "Epoch 4/5\n",
            "36/36 [==============================] - 219s 6s/step - loss: 0.6569 - accuracy: 0.7111 - val_loss: 0.7587 - val_accuracy: 0.6733\n",
            "Epoch 5/5\n",
            "36/36 [==============================] - 218s 6s/step - loss: 0.5106 - accuracy: 0.7305 - val_loss: 0.5601 - val_accuracy: 0.7610\n",
            "Epoch 1/5\n",
            "36/36 [==============================] - 225s 6s/step - loss: 2.4576 - accuracy: 0.5933 - val_loss: 0.9531 - val_accuracy: 0.6135\n",
            "Epoch 2/5\n",
            "36/36 [==============================] - 220s 6s/step - loss: 0.7391 - accuracy: 0.6962 - val_loss: 0.4881 - val_accuracy: 0.7849\n",
            "Epoch 3/5\n",
            "36/36 [==============================] - 220s 6s/step - loss: 0.5281 - accuracy: 0.7617 - val_loss: 0.8379 - val_accuracy: 0.7092\n",
            "Epoch 4/5\n",
            "36/36 [==============================] - 221s 6s/step - loss: 0.5718 - accuracy: 0.7204 - val_loss: 0.7139 - val_accuracy: 0.6932\n",
            "Epoch 5/5\n",
            "36/36 [==============================] - 220s 6s/step - loss: 0.4979 - accuracy: 0.7578 - val_loss: 0.4770 - val_accuracy: 0.7888\n",
            "resnet_best_test_accuracy: 0.7888446215139442\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b55ceae3b6f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;31m# RESULTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception_training_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"InceptionV3 Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"InceptionV3 Accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_training_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ResNet50 Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ResNet50 Accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inception_training_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ3ONuNIxfGE"
      },
      "source": [
        "### Statistical tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A3zVI4txj2w"
      },
      "source": [
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "import numpy as np\n",
        "\n",
        "labels = [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
        "pred_a = [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
        "pred_b = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "correct_a = np.equal(labels, pred_a)\n",
        "correct_b = np.equal(labels, pred_b)\n",
        "\n",
        "count_y_y, count_n_y, count_y_n, count_n_n = 0, 0, 0, 0\n",
        "for i in range(len(correct_a)):\n",
        "    if correct_a[i] == correct_b[i] and correct_a[i] == True:\n",
        "        count_y_y += 1\n",
        "    elif correct_a[i] == correct_b[i] and correct_a[i] == False:\n",
        "        count_n_n += 1\n",
        "    elif correct_a[i] != correct_b[i] and correct_a[i] == True:\n",
        "        count_y_n += 1\n",
        "    elif correct_a[i] != correct_b[i] and correct_a[i] == False:\n",
        "        count_n_y += 1\n",
        "\n",
        "con_table = [[count_y_y, count_y_n], [count_n_y, count_n_n]]\n",
        "# con_table = [[100,150], [100,20]]\n",
        "result = mcnemar(con_table, exact=True)\n",
        "print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
        "# interpret the p-value\n",
        "alpha = 0.05\n",
        "if result.pvalue > alpha:\n",
        "    print('Same proportions of errors (fail to reject H0)')\n",
        "else:\n",
        "    print('Different proportions of errors (reject H0)')\n",
        "\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "d = correct_b.astype(int) - correct_a.astype(int)\n",
        "w, p = wilcoxon(d, alternative='greater')\n",
        "print(f\"w: {w}, p-value: {p}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}